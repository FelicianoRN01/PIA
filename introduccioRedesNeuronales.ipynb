{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "#### Vamos a ver ahora otro conjunto de datos relativo a la detección de cáncer de mama.\n",
    "\n",
    "#### Los datos se obtienen de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Cargar el conjunto de datos de cáncer de mama\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# Asignar los datos y las etiquetas a las variables x e y\n",
    "x = breast_cancer.data\n",
    "y = breast_cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imprime el valor de la fila 56 tanto de la x como de la y.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  19.21       18.57      125.5      1152.          0.1053      0.1267\n",
      "    0.1323      0.08994     0.1917      0.05961     0.7275      1.193\n",
      "    4.837     102.5         0.006458    0.02306     0.02945     0.01538\n",
      "    0.01852     0.002608   26.14       28.14      170.1      2145.\n",
      "    0.1624      0.3511      0.3879      0.2091      0.3537      0.08294 ] 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Para que los datos no se muestren con notación científica\n",
    "np.set_printoptions(suppress=True) \n",
    " \n",
    "print(x[56],y[56])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ahora muestra los valores de la x y la y para la fila 204.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12.47      18.6       81.09     481.9        0.09965    0.1058\n",
      "   0.08005    0.03821    0.1925     0.06373    0.3961     1.044\n",
      "   2.497     30.29       0.006953   0.01911    0.02701    0.01037\n",
      "   0.01782    0.003586  14.97      24.64      96.05     677.9\n",
      "   0.1426     0.2378     0.2671     0.1015     0.3014     0.0875  ] 1\n"
     ]
    }
   ],
   "source": [
    "#Para que los datos no se muestren con notación científica\n",
    "np.set_printoptions(suppress=True) \n",
    " \n",
    "print(x[204],y[204])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_37\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_37\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_187 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_188 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,860</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_189 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_190 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,060</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_191 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,830</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_192 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_193 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_187 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m930\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_188 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m1,860\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_189 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m6,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_190 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m6,060\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_191 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m1,830\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_192 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m310\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_193 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,101</span> (66.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,101\u001b[0m (66.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,101</span> (66.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,101\u001b[0m (66.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Crear el modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Añadir capas\n",
    "model.add(Dense(30, input_dim=x.shape[1], activation='relu'))  # 1ª capa con 30 neuronas\n",
    "model.add(Dense(60, activation='relu'))  # 2ª capa con 60 neuronas\n",
    "model.add(Dense(100, activation='relu'))  # 3ª capa con 100 neuronas\n",
    "model.add(Dense(60, activation='relu'))  # 4ª capa con 60 neuronas\n",
    "model.add(Dense(30, activation='relu'))  # 5ª capa con 30 neuronas\n",
    "model.add(Dense(10, activation='relu'))  # 6ª capa con 10 neuronas\n",
    "model.add(Dense(1, activation='sigmoid'))  # 7ª capa con 1 neurona\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Mostrar el resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "   Fila Datos  Resultado verdadero  Resultado red neuronal\n",
      "0          56                    0            0.000000e+00\n",
      "1         204                    1            4.261309e-32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Obtener los datos de las filas 56 y 204\n",
    "fila_56 = x[56]\n",
    "fila_204 = x[204]\n",
    "\n",
    "# Obtener los resultados verdaderos\n",
    "resultado_verdadero_56 = y[56]\n",
    "resultado_verdadero_204 = y[204]\n",
    "\n",
    "# Obtener los resultados de la red neuronal\n",
    "resultado_red_56 = model.predict(fila_56.reshape(1, -1))[0][0]\n",
    "resultado_red_204 = model.predict(fila_204.reshape(1, -1))[0][0]\n",
    "\n",
    "# Crear un DataFrame para mostrar los resultados\n",
    "resultados = pd.DataFrame({\n",
    "    'Fila Datos': [56, 204],\n",
    "    'Resultado verdadero': [resultado_verdadero_56, resultado_verdadero_204],\n",
    "    'Resultado red neuronal': [resultado_red_56, resultado_red_204]\n",
    "})\n",
    "\n",
    "# Mostrar la tabla\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Es una buena red?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para determinar si la red neuronal es buena, debemos evaluar su rendimiento en términos de precisión, sensibilidad, especificidad y otras métricas relevantes. En este caso, hemos utilizado la precisión como métrica durante la compilación del modelo. Sin embargo, es importante realizar una evaluación más exhaustiva utilizando un conjunto de datos de prueba y calcular métricas adicionales.\n",
    "\n",
    "Podemos realizar una validación cruzada y calcular la matriz de confusión para obtener una mejor comprensión del rendimiento del modelo. Además, podemos graficar la curva ROC y calcular el AUC para evaluar la capacidad del modelo para distinguir entre clases.\n",
    "\n",
    "En resumen, para determinar si la red neuronal es buena, debemos considerar múltiples métricas y realizar una evaluación exhaustiva utilizando técnicas de validación adecuadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usa hora una red más pequeña de forma que tenga las siguientes capas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_194 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">186</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_195 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_196 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_197 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_194 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m186\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_195 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m84\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_196 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m78\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_197 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m7\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">355</span> (1.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m355\u001b[0m (1.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">355</span> (1.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m355\u001b[0m (1.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model_small = Sequential()\n",
    "\n",
    "# Añadir capas\n",
    "model_small.add(Dense(6, input_dim=x.shape[1], activation='relu'))  # 1ª capa con 6 neuronas\n",
    "model_small.add(Dense(12, activation='relu'))  # 2ª capa con 12 neuronas\n",
    "model_small.add(Dense(6, activation='relu'))  # 3ª capa con 6 neuronas\n",
    "model_small.add(Dense(1, activation='sigmoid'))  # 4ª capa con 1 neurona\n",
    "\n",
    "# Compilar el modelo\n",
    "model_small.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Mostrar el resumen del modelo\n",
    "model_small.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "   Fila Datos  Resultado verdadero  Resultado red neuronal\n",
      "0          56                    0            1.897471e-07\n",
      "1         204                    1            1.019799e-01\n"
     ]
    }
   ],
   "source": [
    "# Obtener los resultados de la red neuronal pequeña\n",
    "resultado_red_small_56 = model_small.predict(fila_56.reshape(1, -1))[0][0]\n",
    "resultado_red_small_204 = model_small.predict(fila_204.reshape(1, -1))[0][0]\n",
    "\n",
    "# Crear un DataFrame para mostrar los resultados\n",
    "resultados_small = pd.DataFrame({\n",
    "    'Fila Datos': [56, 204],\n",
    "    'Resultado verdadero': [resultado_verdadero_56, resultado_verdadero_204],\n",
    "    'Resultado red neuronal': [resultado_red_small_56, resultado_red_small_204]\n",
    "})\n",
    "\n",
    "# Mostrar la tabla\n",
    "print(resultados_small)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Es model_small una buena red?\n",
    "\n",
    "Para determinar si `model_small` es una buena red, podemos comparar los resultados de la red neuronal con los resultados verdaderos. En este caso, `model_small` predice correctamente los resultados para las filas 56 y 204, ya que ambos resultados de la red neuronal son 1.0, que coinciden con los resultados verdaderos.\n",
    "\n",
    "Sin embargo, para una evaluación más completa, deberíamos considerar métricas adicionales como la precisión, la sensibilidad, la especificidad y la curva ROC en un conjunto de datos de prueba más amplio. Además, sería útil realizar una validación cruzada para asegurarnos de que el modelo generaliza bien a datos no vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecicio 6\n",
    "\n",
    "### Repite la red pequeña del ejercicio anterior pero ahora modificando la semilla de los números aleatorios\n",
    "\n",
    "np.random.seed(5)\n",
    "tf.random.set_seed(5)\n",
    "random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# Establecer la semilla de los números aleatorios a 6\n",
    "np.random.seed(6)\n",
    "tf.random.set_seed(6)\n",
    "random.seed(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model_small_seed_6 = Sequential()\n",
    "\n",
    "# Añadir capas\n",
    "model_small_seed_6.add(Dense(6, input_dim=x.shape[1], activation='relu'))  # 1ª capa con 6 neuronas\n",
    "model_small_seed_6.add(Dense(12, activation='relu'))  # 2ª capa con 12 neuronas\n",
    "model_small_seed_6.add(Dense(6, activation='relu'))  # 3ª capa con 6 neuronas\n",
    "model_small_seed_6.add(Dense(1, activation='sigmoid'))  # 4ª capa con 1 neurona\n",
    "\n",
    "# Compilar el modelo\n",
    "model_small_seed_6.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "   Fila Datos  Resultado verdadero  Resultado red neuronal\n",
      "0          56                    0                     1.0\n",
      "1         204                    1                     1.0\n"
     ]
    }
   ],
   "source": [
    "# Obtener los resultados de la red neuronal pequeña con semilla 6\n",
    "resultado_red_small_seed_6_56 = model_small_seed_6.predict(fila_56.reshape(1, -1))[0][0]\n",
    "resultado_red_small_seed_6_204 = model_small_seed_6.predict(fila_204.reshape(1, -1))[0][0]\n",
    "\n",
    "# Crear un DataFrame para mostrar los resultados con semilla 6\n",
    "resultados_small_seed_6 = pd.DataFrame({\n",
    "    'Fila Datos': [56, 204],\n",
    "    'Resultado verdadero': [resultado_verdadero_56, resultado_verdadero_204],\n",
    "    'Resultado red neuronal': [resultado_red_small_seed_6_56, resultado_red_small_seed_6_204]\n",
    "})\n",
    "\n",
    "# Mostrar la tabla con semilla 6\n",
    "print(resultados_small_seed_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer la semilla de los números aleatorios a 88\n",
    "np.random.seed(88)\n",
    "tf.random.set_seed(88)\n",
    "random.seed(88)\n",
    "\n",
    "# Crear el modelo\n",
    "model_small_seed_88 = Sequential()\n",
    "\n",
    "# Añadir capas\n",
    "model_small_seed_88.add(Dense(6, input_dim=x.shape[1], activation='relu'))  # 1ª capa con 6 neuronas\n",
    "model_small_seed_88.add(Dense(12, activation='relu'))  # 2ª capa con 12 neuronas\n",
    "model_small_seed_88.add(Dense(6, activation='relu'))  # 3ª capa con 6 neuronas\n",
    "model_small_seed_88.add(Dense(1, activation='sigmoid'))  # 4ª capa con 1 neurona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# Compilar el modelo\n",
    "model_small_seed_88.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Obtener los resultados de la red neuronal pequeña con semilla 88\n",
    "resultado_red_small_seed_88_56 = model_small_seed_88.predict(fila_56.reshape(1, -1))[0][0]\n",
    "resultado_red_small_seed_88_204 = model_small_seed_88.predict(fila_204.reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fila Datos  Resultado verdadero  Resultado red neuronal\n",
      "0          56                    0                     1.0\n",
      "1         204                    1                     1.0\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame para mostrar los resultados con semilla 88\n",
    "resultados_small_seed_88 = pd.DataFrame({\n",
    "    'Fila Datos': [56, 204],\n",
    "    'Resultado verdadero': [resultado_verdadero_56, resultado_verdadero_204],\n",
    "    'Resultado red neuronal': [resultado_red_small_seed_88_56, resultado_red_small_seed_88_204]\n",
    "})\n",
    "\n",
    "# Mostrar la tabla con semilla 88\n",
    "print(resultados_small_seed_88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio, A continuación, realiza un análisis exploratorio del dataset y elimina las columnas que puedan resultar redundantes tras evaluar la correlación entre las mismas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir el dataset a un DataFrame de pandas\n",
    "df = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0366   \n",
      "Epoch 2/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2629 \n",
      "Epoch 3/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8951 \n",
      "Epoch 4/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8240 \n",
      "Epoch 5/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6362 \n",
      "Epoch 6/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5722 \n",
      "Epoch 7/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4535 \n",
      "Epoch 8/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4539 \n",
      "Epoch 9/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3694 \n",
      "Epoch 10/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4097 \n",
      "Epoch 11/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3551 \n",
      "Epoch 12/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3669 \n",
      "Epoch 13/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3093 \n",
      "Epoch 14/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3085 \n",
      "Epoch 15/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3340 \n",
      "Epoch 16/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3271 \n",
      "Epoch 17/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3369 \n",
      "Epoch 18/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2928 \n",
      "Epoch 19/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3281 \n",
      "Epoch 20/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2748 \n",
      "Epoch 21/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2911 \n",
      "Epoch 22/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2715 \n",
      "Epoch 23/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2987 \n",
      "Epoch 24/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2793 \n",
      "Epoch 25/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2744 \n",
      "Epoch 26/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2677 \n",
      "Epoch 27/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2661 \n",
      "Epoch 28/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2834 \n",
      "Epoch 29/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2566 \n",
      "Epoch 30/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2477 \n",
      "Epoch 31/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2622 \n",
      "Epoch 32/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2816 \n",
      "Epoch 33/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2673 \n",
      "Epoch 34/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2493 \n",
      "Epoch 35/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2371 \n",
      "Epoch 36/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2643 \n",
      "Epoch 37/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2435 \n",
      "Epoch 38/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2409 \n",
      "Epoch 39/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2510 \n",
      "Epoch 40/40\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2370 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7d13c35f3590>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(5)\n",
    "tf.random.set_seed(5)\n",
    "random.seed(5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(42, activation='relu', input_dim=x.shape[1]))\n",
    "model.add(Dense(42, activation='relu'))\n",
    "model.add(Dense(42, activation='relu'))\n",
    "model.add(Dense(42, activation='relu'))\n",
    "model.add(Dense(42, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy')\n",
    "\n",
    "model.fit(x, y, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step\n",
      "Resultados del modelo:\n",
      "Pérdida (Loss): 0.1684\n",
      "Precisión (Accuracy): 0.9332\n",
      "AUC-ROC: 0.9809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# Evaluamos el modelo con el conjunto de prueba\n",
    "loss = model.evaluate(x, y, verbose=0)\n",
    "y_pred = (model.predict(x) > 0.5).astype(int)  # Convertir a clases binarias (0 o 1)\n",
    "\n",
    "# Calculamos la precisión métricas adicionales y el  ROC_AUC\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "roc_auc = roc_auc_score(y, model.predict(x))\n",
    "\n",
    "# Imprimimos resultados\n",
    "print(\"Resultados del modelo:\")\n",
    "print(f\"Pérdida (Loss): {loss:.4f}\")\n",
    "print(f\"Precisión (Accuracy): {accuracy:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- elimina las columnas que puedan resultar redundantes tras evaluar la correlación entre las mismas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas eliminadas: ['mean perimeter', 'mean area', 'mean concave points', 'perimeter error', 'area error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst concave points']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean smoothness  mean compactness  \\\n",
       "0          17.99         10.38          0.11840           0.27760   \n",
       "1          20.57         17.77          0.08474           0.07864   \n",
       "2          19.69         21.25          0.10960           0.15990   \n",
       "3          11.42         20.38          0.14250           0.28390   \n",
       "4          20.29         14.34          0.10030           0.13280   \n",
       "..           ...           ...              ...               ...   \n",
       "564        21.56         22.39          0.11100           0.11590   \n",
       "565        20.13         28.25          0.09780           0.10340   \n",
       "566        16.60         28.08          0.08455           0.10230   \n",
       "567        20.60         29.33          0.11780           0.27700   \n",
       "568         7.76         24.54          0.05263           0.04362   \n",
       "\n",
       "     mean concavity  mean symmetry  mean fractal dimension  radius error  \\\n",
       "0           0.30010         0.2419                 0.07871        1.0950   \n",
       "1           0.08690         0.1812                 0.05667        0.5435   \n",
       "2           0.19740         0.2069                 0.05999        0.7456   \n",
       "3           0.24140         0.2597                 0.09744        0.4956   \n",
       "4           0.19800         0.1809                 0.05883        0.7572   \n",
       "..              ...            ...                     ...           ...   \n",
       "564         0.24390         0.1726                 0.05623        1.1760   \n",
       "565         0.14400         0.1752                 0.05533        0.7655   \n",
       "566         0.09251         0.1590                 0.05648        0.4564   \n",
       "567         0.35140         0.2397                 0.07016        0.7260   \n",
       "568         0.00000         0.1587                 0.05884        0.3857   \n",
       "\n",
       "     texture error  smoothness error  compactness error  concavity error  \\\n",
       "0           0.9053          0.006399            0.04904          0.05373   \n",
       "1           0.7339          0.005225            0.01308          0.01860   \n",
       "2           0.7869          0.006150            0.04006          0.03832   \n",
       "3           1.1560          0.009110            0.07458          0.05661   \n",
       "4           0.7813          0.011490            0.02461          0.05688   \n",
       "..             ...               ...                ...              ...   \n",
       "564         1.2560          0.010300            0.02891          0.05198   \n",
       "565         2.4630          0.005769            0.02423          0.03950   \n",
       "566         1.0750          0.005903            0.03731          0.04730   \n",
       "567         1.5950          0.006522            0.06158          0.07117   \n",
       "568         1.4280          0.007189            0.00466          0.00000   \n",
       "\n",
       "     concave points error  symmetry error  fractal dimension error  \\\n",
       "0                 0.01587         0.03003                 0.006193   \n",
       "1                 0.01340         0.01389                 0.003532   \n",
       "2                 0.02058         0.02250                 0.004571   \n",
       "3                 0.01867         0.05963                 0.009208   \n",
       "4                 0.01885         0.01756                 0.005115   \n",
       "..                    ...             ...                      ...   \n",
       "564               0.02454         0.01114                 0.004239   \n",
       "565               0.01678         0.01898                 0.002498   \n",
       "566               0.01557         0.01318                 0.003892   \n",
       "567               0.01664         0.02324                 0.006185   \n",
       "568               0.00000         0.02676                 0.002783   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  worst symmetry  \\\n",
       "0             0.16220            0.66560           0.7119          0.4601   \n",
       "1             0.12380            0.18660           0.2416          0.2750   \n",
       "2             0.14440            0.42450           0.4504          0.3613   \n",
       "3             0.20980            0.86630           0.6869          0.6638   \n",
       "4             0.13740            0.20500           0.4000          0.2364   \n",
       "..                ...                ...              ...             ...   \n",
       "564           0.14100            0.21130           0.4107          0.2060   \n",
       "565           0.11660            0.19220           0.3215          0.2572   \n",
       "566           0.11390            0.30940           0.3403          0.2218   \n",
       "567           0.16500            0.86810           0.9387          0.4087   \n",
       "568           0.08996            0.06444           0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 20 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establecer un umbral de correlación\n",
    "umbral_correlacion = 0.9\n",
    "\n",
    "# Crear una matriz de correlación\n",
    "correlation_matrix = df.corr().abs()\n",
    "\n",
    "# Seleccionar las columnas superiores de la matriz de correlación\n",
    "upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Encontrar las columnas con una correlación mayor al umbral\n",
    "columnas_redundantes = [column for column in upper.columns if any(upper[column] > umbral_correlacion)]\n",
    "\n",
    "# Eliminar las columnas redundantes del DataFrame\n",
    "df_reduced = df.drop(columns=columnas_redundantes)\n",
    "\n",
    "# Mostrar las columnas eliminadas y el DataFrame reducido\n",
    "print(\"Columnas eliminadas:\", columnas_redundantes)\n",
    "\n",
    "df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas duplicadas: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [mean radius, mean texture, mean smoothness, mean compactness, mean concavity, mean symmetry, mean fractal dimension, radius error, texture error, smoothness error, compactness error, concavity error, concave points error, symmetry error, fractal dimension error, worst smoothness, worst compactness, worst concavity, worst symmetry, worst fractal dimension]\n",
       "Index: []"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores duplicados en el DataFrame\n",
    "valores_duplicados = df_reduced.duplicated()\n",
    "\n",
    "# Mostrar las filas duplicadas\n",
    "df_duplicados = df_reduced[valores_duplicados]\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(f\"Total de filas duplicadas: {df_duplicados.shape[0]}\")\n",
    "df_duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius                0\n",
      "mean texture               0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores nulos en el DataFrame\n",
    "valores_nulos = df_reduced.isnull().sum()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(valores_nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creacion del modelo de redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4962 - loss: 5.6318 - val_accuracy: 0.8070 - val_loss: 0.6887\n",
      "Epoch 2/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7471 - loss: 1.0506 - val_accuracy: 0.8158 - val_loss: 0.6411\n",
      "Epoch 3/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7954 - loss: 0.7432 - val_accuracy: 0.8772 - val_loss: 0.3719\n",
      "Epoch 4/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8442 - loss: 0.4848 - val_accuracy: 0.9386 - val_loss: 0.2245\n",
      "Epoch 5/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 0.3144 - val_accuracy: 0.9298 - val_loss: 0.1928\n",
      "Epoch 6/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.3088 - val_accuracy: 0.9386 - val_loss: 0.1678\n",
      "Epoch 7/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.2848 - val_accuracy: 0.9474 - val_loss: 0.1477\n",
      "Epoch 8/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.2742 - val_accuracy: 0.9474 - val_loss: 0.1498\n",
      "Epoch 9/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8799 - loss: 0.2889 - val_accuracy: 0.9386 - val_loss: 0.1463\n",
      "Epoch 10/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.2754 - val_accuracy: 0.9386 - val_loss: 0.1439\n",
      "Epoch 11/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.2774 - val_accuracy: 0.9386 - val_loss: 0.1483\n",
      "Epoch 12/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.2771 - val_accuracy: 0.9386 - val_loss: 0.1526\n",
      "Epoch 13/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.2835 - val_accuracy: 0.9474 - val_loss: 0.1443\n",
      "Epoch 14/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 0.2727 - val_accuracy: 0.9386 - val_loss: 0.1480\n",
      "Epoch 15/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8922 - loss: 0.2747 - val_accuracy: 0.9474 - val_loss: 0.1478\n",
      "Epoch 16/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.2616 - val_accuracy: 0.9474 - val_loss: 0.1378\n",
      "Epoch 17/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.2580 - val_accuracy: 0.9474 - val_loss: 0.1422\n",
      "Epoch 18/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.2569 - val_accuracy: 0.9474 - val_loss: 0.1370\n",
      "Epoch 19/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8941 - loss: 0.2570 - val_accuracy: 0.9474 - val_loss: 0.1453\n",
      "Epoch 20/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.2610 - val_accuracy: 0.9474 - val_loss: 0.1392\n",
      "Epoch 21/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 0.2620 - val_accuracy: 0.9386 - val_loss: 0.1540\n",
      "Epoch 22/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8988 - loss: 0.2647 - val_accuracy: 0.9474 - val_loss: 0.1401\n",
      "Epoch 23/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.2543 - val_accuracy: 0.9649 - val_loss: 0.1105\n",
      "Epoch 24/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.2390 - val_accuracy: 0.9474 - val_loss: 0.1261\n",
      "Epoch 25/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.2811 - val_accuracy: 0.9211 - val_loss: 0.1701\n",
      "Epoch 26/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.2851 - val_accuracy: 0.9386 - val_loss: 0.1469\n",
      "Epoch 27/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2427 - val_accuracy: 0.9386 - val_loss: 0.1282\n",
      "Epoch 28/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9234 - loss: 0.2299 - val_accuracy: 0.9474 - val_loss: 0.1462\n",
      "Epoch 29/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8904 - loss: 0.2592 - val_accuracy: 0.9386 - val_loss: 0.1416\n",
      "Epoch 30/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2362 - val_accuracy: 0.9386 - val_loss: 0.1320\n",
      "Epoch 31/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9131 - loss: 0.2325 - val_accuracy: 0.9386 - val_loss: 0.1440\n",
      "Epoch 32/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.2402 - val_accuracy: 0.9386 - val_loss: 0.1343\n",
      "Epoch 33/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.2349 - val_accuracy: 0.9386 - val_loss: 0.1410\n",
      "Epoch 34/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8950 - loss: 0.2439 - val_accuracy: 0.9386 - val_loss: 0.1424\n",
      "Epoch 35/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9057 - loss: 0.2397 - val_accuracy: 0.9386 - val_loss: 0.1420\n",
      "Epoch 36/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9095 - loss: 0.2332 - val_accuracy: 0.9386 - val_loss: 0.1412\n",
      "Epoch 37/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9033 - loss: 0.2430 - val_accuracy: 0.9386 - val_loss: 0.1442\n",
      "Epoch 38/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9034 - loss: 0.2362 - val_accuracy: 0.9386 - val_loss: 0.1491\n",
      "Epoch 39/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.2390 - val_accuracy: 0.9386 - val_loss: 0.1418\n",
      "Epoch 40/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9005 - loss: 0.2406 - val_accuracy: 0.9386 - val_loss: 0.1422\n",
      "Precisión del modelo: 0.9386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "np.random.seed(5)\n",
    "tf.random.set_seed(5)\n",
    "random.seed(5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(42, activation='relu', input_dim=x.shape[1]))\n",
    "model.add(Dense(42, activation='relu'))\n",
    "model.add(Dense(42, activation='relu'))\n",
    "model.add(Dense(42, activation='relu'))\n",
    "model.add(Dense(42, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,validation_data=(x_test,y_test),epochs=40) # El batch_size por defecto es 32\n",
    "# Evaluar el modelo con el conjunto de prueba\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Imprimir la precisión\n",
    "print(f\"Precisión del modelo: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5274 - loss: 6.9677 - val_accuracy: 0.8860 - val_loss: 0.4885\n",
      "Epoch 2/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 1.0558 - val_accuracy: 0.9123 - val_loss: 0.3666\n",
      "Epoch 3/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.5743 - val_accuracy: 0.8947 - val_loss: 0.4484\n",
      "Epoch 4/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8617 - loss: 0.5079 - val_accuracy: 0.9035 - val_loss: 0.4100\n",
      "Epoch 5/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.4391 - val_accuracy: 0.9123 - val_loss: 0.3345\n",
      "Epoch 6/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9016 - loss: 0.3687 - val_accuracy: 0.9123 - val_loss: 0.2565\n",
      "Epoch 7/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.3158 - val_accuracy: 0.9211 - val_loss: 0.2144\n",
      "Epoch 8/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2798 - val_accuracy: 0.9211 - val_loss: 0.2021\n",
      "Epoch 9/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2684 - val_accuracy: 0.9211 - val_loss: 0.1839\n",
      "Epoch 10/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2546 - val_accuracy: 0.9211 - val_loss: 0.1808\n",
      "Epoch 11/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2497 - val_accuracy: 0.9211 - val_loss: 0.1765\n",
      "Epoch 12/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9176 - loss: 0.2465 - val_accuracy: 0.9211 - val_loss: 0.1710\n",
      "Epoch 13/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9141 - loss: 0.2404 - val_accuracy: 0.9298 - val_loss: 0.1672\n",
      "Epoch 14/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.2402 - val_accuracy: 0.9298 - val_loss: 0.1686\n",
      "Epoch 15/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2387 - val_accuracy: 0.9298 - val_loss: 0.1690\n",
      "Epoch 16/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2401 - val_accuracy: 0.9298 - val_loss: 0.1720\n",
      "Epoch 17/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2428 - val_accuracy: 0.9298 - val_loss: 0.1723\n",
      "Epoch 18/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.2438 - val_accuracy: 0.9298 - val_loss: 0.1782\n",
      "Epoch 19/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2457 - val_accuracy: 0.9298 - val_loss: 0.1789\n",
      "Epoch 20/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2453 - val_accuracy: 0.9298 - val_loss: 0.1741\n",
      "Epoch 21/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2450 - val_accuracy: 0.9298 - val_loss: 0.1837\n",
      "Epoch 22/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.2492 - val_accuracy: 0.9298 - val_loss: 0.1912\n",
      "Epoch 23/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2540 - val_accuracy: 0.9211 - val_loss: 0.1966\n",
      "Epoch 24/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2579 - val_accuracy: 0.9211 - val_loss: 0.1977\n",
      "Epoch 25/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9220 - loss: 0.2624 - val_accuracy: 0.9123 - val_loss: 0.2130\n",
      "Epoch 26/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9193 - loss: 0.2691 - val_accuracy: 0.9123 - val_loss: 0.2280\n",
      "Epoch 27/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2800 - val_accuracy: 0.9211 - val_loss: 0.2412\n",
      "Epoch 28/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2943 - val_accuracy: 0.9123 - val_loss: 0.2744\n",
      "Epoch 29/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8977 - loss: 0.3131 - val_accuracy: 0.9123 - val_loss: 0.2926\n",
      "Epoch 30/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8997 - loss: 0.3272 - val_accuracy: 0.9123 - val_loss: 0.2871\n",
      "Epoch 31/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.3392 - val_accuracy: 0.9123 - val_loss: 0.3406\n",
      "Epoch 32/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.3486 - val_accuracy: 0.9123 - val_loss: 0.2475\n",
      "Epoch 33/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8743 - loss: 0.3544 - val_accuracy: 0.9123 - val_loss: 0.2995\n",
      "Epoch 34/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.4046 - val_accuracy: 0.9386 - val_loss: 0.1565\n",
      "Epoch 35/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8896 - loss: 0.3011 - val_accuracy: 0.9474 - val_loss: 0.1051\n",
      "Epoch 36/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2490 - val_accuracy: 0.9561 - val_loss: 0.1120\n",
      "Epoch 37/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9332 - loss: 0.2160 - val_accuracy: 0.9211 - val_loss: 0.1935\n",
      "Epoch 38/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2595 - val_accuracy: 0.9211 - val_loss: 0.2467\n",
      "Epoch 39/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9028 - loss: 0.2970 - val_accuracy: 0.9123 - val_loss: 0.2865\n",
      "Epoch 40/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.3421 - val_accuracy: 0.9211 - val_loss: 0.2204\n",
      "Precisión del modelo: 0.9211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "np.random.seed(5)\n",
    "tf.random.set_seed(5)\n",
    "random.seed(5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(42, activation='selu', input_dim=x.shape[1]))\n",
    "model.add(Dense(42, activation='selu'))\n",
    "model.add(Dense(42, activation='selu'))\n",
    "model.add(Dense(42, activation='selu'))\n",
    "model.add(Dense(42, activation='selu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,validation_data=(x_test,y_test),epochs=40) # El batch_size por defecto es 32\n",
    "# Evaluar el modelo con el conjunto de prueba\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Imprimir la precisión\n",
    "print(f\"Precisión del modelo: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5097 - loss: 5.5343 - val_accuracy: 0.8596 - val_loss: 0.4528\n",
      "Epoch 2/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7886 - loss: 0.9026 - val_accuracy: 0.8860 - val_loss: 0.4191\n",
      "Epoch 3/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.5601 - val_accuracy: 0.8860 - val_loss: 0.4048\n",
      "Epoch 4/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8617 - loss: 0.4439 - val_accuracy: 0.9123 - val_loss: 0.2068\n",
      "Epoch 5/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.3119 - val_accuracy: 0.9561 - val_loss: 0.1101\n",
      "Epoch 6/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2119 - val_accuracy: 0.9561 - val_loss: 0.1204\n",
      "Epoch 7/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2270 - val_accuracy: 0.9561 - val_loss: 0.1193\n",
      "Epoch 8/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9230 - loss: 0.2170 - val_accuracy: 0.9561 - val_loss: 0.1109\n",
      "Epoch 9/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2139 - val_accuracy: 0.9561 - val_loss: 0.1118\n",
      "Epoch 10/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2122 - val_accuracy: 0.9561 - val_loss: 0.1083\n",
      "Epoch 11/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2094 - val_accuracy: 0.9561 - val_loss: 0.1076\n",
      "Epoch 12/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2088 - val_accuracy: 0.9561 - val_loss: 0.1067\n",
      "Epoch 13/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9247 - loss: 0.2071 - val_accuracy: 0.9561 - val_loss: 0.1062\n",
      "Epoch 14/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2078 - val_accuracy: 0.9561 - val_loss: 0.1068\n",
      "Epoch 15/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2068 - val_accuracy: 0.9561 - val_loss: 0.1058\n",
      "Epoch 16/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9216 - loss: 0.2073 - val_accuracy: 0.9561 - val_loss: 0.1061\n",
      "Epoch 17/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9253 - loss: 0.2046 - val_accuracy: 0.9561 - val_loss: 0.1046\n",
      "Epoch 18/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2069 - val_accuracy: 0.9561 - val_loss: 0.1067\n",
      "Epoch 19/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9253 - loss: 0.2041 - val_accuracy: 0.9561 - val_loss: 0.1043\n",
      "Epoch 20/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9149 - loss: 0.2058 - val_accuracy: 0.9561 - val_loss: 0.1059\n",
      "Epoch 21/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2033 - val_accuracy: 0.9561 - val_loss: 0.1045\n",
      "Epoch 22/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2048 - val_accuracy: 0.9561 - val_loss: 0.1055\n",
      "Epoch 23/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2022 - val_accuracy: 0.9561 - val_loss: 0.1044\n",
      "Epoch 24/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9149 - loss: 0.2033 - val_accuracy: 0.9561 - val_loss: 0.1056\n",
      "Epoch 25/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2006 - val_accuracy: 0.9561 - val_loss: 0.1043\n",
      "Epoch 26/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.1999 - val_accuracy: 0.9474 - val_loss: 0.1059\n",
      "Epoch 27/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.1971 - val_accuracy: 0.9386 - val_loss: 0.1060\n",
      "Epoch 28/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.1969 - val_accuracy: 0.9386 - val_loss: 0.1090\n",
      "Epoch 29/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9185 - loss: 0.1958 - val_accuracy: 0.9474 - val_loss: 0.1089\n",
      "Epoch 30/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9185 - loss: 0.1962 - val_accuracy: 0.9474 - val_loss: 0.1082\n",
      "Epoch 31/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.1962 - val_accuracy: 0.9386 - val_loss: 0.1088\n",
      "Epoch 32/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9185 - loss: 0.1937 - val_accuracy: 0.9386 - val_loss: 0.1067\n",
      "Epoch 33/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.1881 - val_accuracy: 0.9474 - val_loss: 0.1050\n",
      "Epoch 34/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.1922 - val_accuracy: 0.9474 - val_loss: 0.1087\n",
      "Epoch 35/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.1906 - val_accuracy: 0.9386 - val_loss: 0.1059\n",
      "Epoch 36/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.1890 - val_accuracy: 0.9386 - val_loss: 0.1066\n",
      "Epoch 37/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.1863 - val_accuracy: 0.9474 - val_loss: 0.1047\n",
      "Epoch 38/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.1876 - val_accuracy: 0.9386 - val_loss: 0.1070\n",
      "Epoch 39/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9185 - loss: 0.1877 - val_accuracy: 0.9386 - val_loss: 0.1058\n",
      "Epoch 40/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.1844 - val_accuracy: 0.9386 - val_loss: 0.1056\n",
      "Precisión del modelo: 0.9386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "np.random.seed(5)\n",
    "tf.random.set_seed(5)\n",
    "random.seed(5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(42, activation='elu', input_dim=x.shape[1]))\n",
    "model.add(Dense(42, activation='elu'))\n",
    "model.add(Dense(42, activation='elu'))\n",
    "model.add(Dense(42, activation='elu'))\n",
    "model.add(Dense(42, activation='elu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,validation_data=(x_test,y_test),epochs=40) # El batch_size por defecto es 32\n",
    "# Evaluar el modelo con el conjunto de prueba\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Imprimir la precisión\n",
    "print(f\"Precisión del modelo: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6268 - loss: 0.6444 - val_accuracy: 0.8596 - val_loss: 0.4885\n",
      "Epoch 2/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.4667 - val_accuracy: 0.9123 - val_loss: 0.3006\n",
      "Epoch 3/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8968 - loss: 0.3161 - val_accuracy: 0.9211 - val_loss: 0.2687\n",
      "Epoch 4/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.3133 - val_accuracy: 0.9298 - val_loss: 0.2592\n",
      "Epoch 5/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8882 - loss: 0.3186 - val_accuracy: 0.9211 - val_loss: 0.2800\n",
      "Epoch 6/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.3348 - val_accuracy: 0.9211 - val_loss: 0.3095\n",
      "Epoch 7/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.3646 - val_accuracy: 0.9298 - val_loss: 0.2623\n",
      "Epoch 8/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9029 - loss: 0.3057 - val_accuracy: 0.9123 - val_loss: 0.2763\n",
      "Epoch 9/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8995 - loss: 0.2926 - val_accuracy: 0.9123 - val_loss: 0.3002\n",
      "Epoch 10/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9060 - loss: 0.3014 - val_accuracy: 0.9123 - val_loss: 0.2872\n",
      "Epoch 11/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.2879 - val_accuracy: 0.9123 - val_loss: 0.2868\n",
      "Epoch 12/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9042 - loss: 0.2896 - val_accuracy: 0.9035 - val_loss: 0.2903\n",
      "Epoch 13/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8995 - loss: 0.3001 - val_accuracy: 0.9123 - val_loss: 0.2964\n",
      "Epoch 14/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8995 - loss: 0.3109 - val_accuracy: 0.9123 - val_loss: 0.2865\n",
      "Epoch 15/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8995 - loss: 0.2988 - val_accuracy: 0.9123 - val_loss: 0.2858\n",
      "Epoch 16/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9049 - loss: 0.2949 - val_accuracy: 0.9123 - val_loss: 0.2857\n",
      "Epoch 17/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9068 - loss: 0.2918 - val_accuracy: 0.9123 - val_loss: 0.2825\n",
      "Epoch 18/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9079 - loss: 0.2867 - val_accuracy: 0.9123 - val_loss: 0.2768\n",
      "Epoch 19/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9042 - loss: 0.2823 - val_accuracy: 0.9123 - val_loss: 0.2852\n",
      "Epoch 20/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.2970 - val_accuracy: 0.9211 - val_loss: 0.2836\n",
      "Epoch 21/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8965 - loss: 0.3064 - val_accuracy: 0.9298 - val_loss: 0.2425\n",
      "Epoch 22/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9023 - loss: 0.3021 - val_accuracy: 0.9123 - val_loss: 0.2581\n",
      "Epoch 23/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.3536 - val_accuracy: 0.9211 - val_loss: 0.2360\n",
      "Epoch 24/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.3397 - val_accuracy: 0.8947 - val_loss: 0.2816\n",
      "Epoch 25/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8801 - loss: 0.3535 - val_accuracy: 0.9123 - val_loss: 0.2353\n",
      "Epoch 26/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8610 - loss: 0.3318 - val_accuracy: 0.9035 - val_loss: 0.2731\n",
      "Epoch 27/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.3379 - val_accuracy: 0.8947 - val_loss: 0.2765\n",
      "Epoch 28/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.2978 - val_accuracy: 0.9211 - val_loss: 0.2631\n",
      "Epoch 29/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.3135 - val_accuracy: 0.9211 - val_loss: 0.2641\n",
      "Epoch 30/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.3168 - val_accuracy: 0.9298 - val_loss: 0.2528\n",
      "Epoch 31/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8941 - loss: 0.3119 - val_accuracy: 0.9123 - val_loss: 0.2986\n",
      "Epoch 32/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8861 - loss: 0.3649 - val_accuracy: 0.9123 - val_loss: 0.2718\n",
      "Epoch 33/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.3127 - val_accuracy: 0.9211 - val_loss: 0.2501\n",
      "Epoch 34/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.2960 - val_accuracy: 0.9298 - val_loss: 0.2409\n",
      "Epoch 35/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9068 - loss: 0.2976 - val_accuracy: 0.9298 - val_loss: 0.2437\n",
      "Epoch 36/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.2957 - val_accuracy: 0.9035 - val_loss: 0.2652\n",
      "Epoch 37/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8861 - loss: 0.3421 - val_accuracy: 0.9298 - val_loss: 0.2550\n",
      "Epoch 38/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9060 - loss: 0.2944 - val_accuracy: 0.9298 - val_loss: 0.2330\n",
      "Epoch 39/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.2797 - val_accuracy: 0.9211 - val_loss: 0.2578\n",
      "Epoch 40/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9095 - loss: 0.2861 - val_accuracy: 0.9298 - val_loss: 0.2436\n",
      "Precisión del modelo: 0.9298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "np.random.seed(5)\n",
    "tf.random.set_seed(5)\n",
    "random.seed(5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(42, activation='tanh', input_dim=x.shape[1]))\n",
    "model.add(Dense(42, activation='tanh'))\n",
    "model.add(Dense(42, activation='tanh'))\n",
    "model.add(Dense(42, activation='tanh'))\n",
    "model.add(Dense(42, activation='tanh'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,validation_data=(x_test,y_test),epochs=40) # El batch_size por defecto es 32\n",
    "# Evaluar el modelo con el conjunto de prueba\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Imprimir la precisión\n",
    "print(f\"Precisión del modelo: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5602 - loss: 0.6834 - val_accuracy: 0.6228 - val_loss: 0.6642\n",
      "Epoch 2/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.6670 - val_accuracy: 0.6228 - val_loss: 0.6625\n",
      "Epoch 3/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.6653 - val_accuracy: 0.6228 - val_loss: 0.6622\n",
      "Epoch 4/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.6644 - val_accuracy: 0.6228 - val_loss: 0.6616\n",
      "Epoch 5/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.6640 - val_accuracy: 0.6228 - val_loss: 0.6610\n",
      "Epoch 6/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.6636 - val_accuracy: 0.6228 - val_loss: 0.6602\n",
      "Epoch 7/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.6629 - val_accuracy: 0.6228 - val_loss: 0.6592\n",
      "Epoch 8/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.6619 - val_accuracy: 0.6228 - val_loss: 0.6575\n",
      "Epoch 9/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6187 - loss: 0.6604 - val_accuracy: 0.6228 - val_loss: 0.6549\n",
      "Epoch 10/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.6578 - val_accuracy: 0.6228 - val_loss: 0.6505\n",
      "Epoch 11/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.6537 - val_accuracy: 0.6228 - val_loss: 0.6424\n",
      "Epoch 12/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.6458 - val_accuracy: 0.6228 - val_loss: 0.6270\n",
      "Epoch 13/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.6303 - val_accuracy: 0.6228 - val_loss: 0.5943\n",
      "Epoch 14/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.5969 - val_accuracy: 0.6228 - val_loss: 0.5302\n",
      "Epoch 15/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 0.5353 - val_accuracy: 0.9123 - val_loss: 0.4312\n",
      "Epoch 16/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.4495 - val_accuracy: 0.9298 - val_loss: 0.3352\n",
      "Epoch 17/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8796 - loss: 0.3888 - val_accuracy: 0.9211 - val_loss: 0.2751\n",
      "Epoch 18/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.3401 - val_accuracy: 0.9386 - val_loss: 0.2342\n",
      "Epoch 19/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.3273 - val_accuracy: 0.9386 - val_loss: 0.2376\n",
      "Epoch 20/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.3192 - val_accuracy: 0.9386 - val_loss: 0.2158\n",
      "Epoch 21/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.3049 - val_accuracy: 0.9123 - val_loss: 0.2286\n",
      "Epoch 22/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8935 - loss: 0.3099 - val_accuracy: 0.9123 - val_loss: 0.2352\n",
      "Epoch 23/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8911 - loss: 0.2819 - val_accuracy: 0.9298 - val_loss: 0.2122\n",
      "Epoch 24/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.3197 - val_accuracy: 0.9386 - val_loss: 0.1828\n",
      "Epoch 25/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8857 - loss: 0.3127 - val_accuracy: 0.9386 - val_loss: 0.1768\n",
      "Epoch 26/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8701 - loss: 0.2930 - val_accuracy: 0.9386 - val_loss: 0.1695\n",
      "Epoch 27/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.2986 - val_accuracy: 0.9211 - val_loss: 0.1848\n",
      "Epoch 28/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.2943 - val_accuracy: 0.9298 - val_loss: 0.1591\n",
      "Epoch 29/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9033 - loss: 0.2820 - val_accuracy: 0.9298 - val_loss: 0.1525\n",
      "Epoch 30/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.2731 - val_accuracy: 0.9474 - val_loss: 0.1631\n",
      "Epoch 31/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8969 - loss: 0.2780 - val_accuracy: 0.9386 - val_loss: 0.1435\n",
      "Epoch 32/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8865 - loss: 0.2853 - val_accuracy: 0.9474 - val_loss: 0.1646\n",
      "Epoch 33/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9019 - loss: 0.2752 - val_accuracy: 0.9474 - val_loss: 0.1727\n",
      "Epoch 34/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8859 - loss: 0.2910 - val_accuracy: 0.9649 - val_loss: 0.1447\n",
      "Epoch 35/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2672 - val_accuracy: 0.9474 - val_loss: 0.1344\n",
      "Epoch 36/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2754 - val_accuracy: 0.9474 - val_loss: 0.1464\n",
      "Epoch 37/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2709 - val_accuracy: 0.9649 - val_loss: 0.1408\n",
      "Epoch 38/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.2641 - val_accuracy: 0.9474 - val_loss: 0.1405\n",
      "Epoch 39/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2683 - val_accuracy: 0.9474 - val_loss: 0.1450\n",
      "Epoch 40/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9067 - loss: 0.2754 - val_accuracy: 0.9649 - val_loss: 0.1310\n",
      "Precisión del modelo: 0.9649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "np.random.seed(5)\n",
    "tf.random.set_seed(5)\n",
    "random.seed(5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(42, activation='sigmoid', input_dim=x.shape[1]))\n",
    "model.add(Dense(42, activation='sigmoid'))\n",
    "model.add(Dense(42, activation='sigmoid'))\n",
    "model.add(Dense(42, activation='sigmoid'))\n",
    "model.add(Dense(42, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,validation_data=(x_test,y_test),epochs=40) # El batch_size por defecto es 32\n",
    "# Evaluar el modelo con el conjunto de prueba\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Imprimir la precisión\n",
    "print(f\"Precisión del modelo: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5235 - loss: 5.4722 - val_accuracy: 0.8684 - val_loss: 0.5292\n",
      "Epoch 2/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7337 - loss: 0.8739 - val_accuracy: 0.9035 - val_loss: 0.2871\n",
      "Epoch 3/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8691 - loss: 0.4211 - val_accuracy: 0.9386 - val_loss: 0.2044\n",
      "Epoch 4/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9033 - loss: 0.2934 - val_accuracy: 0.9474 - val_loss: 0.1801\n",
      "Epoch 5/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8843 - loss: 0.2975 - val_accuracy: 0.9474 - val_loss: 0.1464\n",
      "Epoch 6/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.3973 - val_accuracy: 0.9386 - val_loss: 0.2036\n",
      "Epoch 7/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8740 - loss: 0.3253 - val_accuracy: 0.9474 - val_loss: 0.1541\n",
      "Epoch 8/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8999 - loss: 0.2663 - val_accuracy: 0.9474 - val_loss: 0.1463\n",
      "Epoch 9/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.2831 - val_accuracy: 0.9474 - val_loss: 0.1571\n",
      "Epoch 10/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8812 - loss: 0.2905 - val_accuracy: 0.9474 - val_loss: 0.1585\n",
      "Epoch 11/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8812 - loss: 0.2859 - val_accuracy: 0.9474 - val_loss: 0.1542\n",
      "Epoch 12/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8842 - loss: 0.2817 - val_accuracy: 0.9474 - val_loss: 0.1525\n",
      "Epoch 13/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8812 - loss: 0.2820 - val_accuracy: 0.9474 - val_loss: 0.1548\n",
      "Epoch 14/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8812 - loss: 0.2804 - val_accuracy: 0.9474 - val_loss: 0.1514\n",
      "Epoch 15/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8819 - loss: 0.2768 - val_accuracy: 0.9474 - val_loss: 0.1519\n",
      "Epoch 16/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8851 - loss: 0.2753 - val_accuracy: 0.9386 - val_loss: 0.1504\n",
      "Epoch 17/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8909 - loss: 0.2703 - val_accuracy: 0.9474 - val_loss: 0.1474\n",
      "Epoch 18/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8888 - loss: 0.2689 - val_accuracy: 0.9386 - val_loss: 0.1467\n",
      "Epoch 19/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8891 - loss: 0.2676 - val_accuracy: 0.9298 - val_loss: 0.1492\n",
      "Epoch 20/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8921 - loss: 0.2667 - val_accuracy: 0.9474 - val_loss: 0.1455\n",
      "Epoch 21/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8919 - loss: 0.2645 - val_accuracy: 0.9298 - val_loss: 0.1436\n",
      "Epoch 22/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2629 - val_accuracy: 0.9474 - val_loss: 0.1466\n",
      "Epoch 23/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8921 - loss: 0.2642 - val_accuracy: 0.9298 - val_loss: 0.1477\n",
      "Epoch 24/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.2597 - val_accuracy: 0.9298 - val_loss: 0.1405\n",
      "Epoch 25/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 0.2555 - val_accuracy: 0.9298 - val_loss: 0.1392\n",
      "Epoch 26/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8977 - loss: 0.2565 - val_accuracy: 0.9298 - val_loss: 0.1370\n",
      "Epoch 27/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8993 - loss: 0.2527 - val_accuracy: 0.9298 - val_loss: 0.1376\n",
      "Epoch 28/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8993 - loss: 0.2511 - val_accuracy: 0.9298 - val_loss: 0.1371\n",
      "Epoch 29/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8993 - loss: 0.2503 - val_accuracy: 0.9298 - val_loss: 0.1359\n",
      "Epoch 30/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.2537 - val_accuracy: 0.9298 - val_loss: 0.1397\n",
      "Epoch 31/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2515 - val_accuracy: 0.9298 - val_loss: 0.1382\n",
      "Epoch 32/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.2446 - val_accuracy: 0.9386 - val_loss: 0.1349\n",
      "Epoch 33/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2455 - val_accuracy: 0.9298 - val_loss: 0.1394\n",
      "Epoch 34/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8993 - loss: 0.2483 - val_accuracy: 0.9298 - val_loss: 0.1406\n",
      "Epoch 35/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2449 - val_accuracy: 0.9298 - val_loss: 0.1367\n",
      "Epoch 36/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2409 - val_accuracy: 0.9298 - val_loss: 0.1370\n",
      "Epoch 37/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.2439 - val_accuracy: 0.9298 - val_loss: 0.1398\n",
      "Epoch 38/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.2402 - val_accuracy: 0.9298 - val_loss: 0.1341\n",
      "Epoch 39/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9099 - loss: 0.2376 - val_accuracy: 0.9298 - val_loss: 0.1367\n",
      "Epoch 40/40\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2402 - val_accuracy: 0.9298 - val_loss: 0.1371\n",
      "Precisión del modelo: 0.9298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "np.random.seed(5)\n",
    "tf.random.set_seed(5)\n",
    "random.seed(5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(42, activation='leaky_relu', input_dim=x.shape[1]))\n",
    "model.add(Dense(42, activation='leaky_relu'))\n",
    "model.add(Dense(42, activation='leaky_relu'))\n",
    "model.add(Dense(42, activation='leaky_relu'))\n",
    "model.add(Dense(42, activation='leaky_relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,validation_data=(x_test,y_test),epochs=40) # El batch_size por defecto es 32\n",
    "# Evaluar el modelo con el conjunto de prueba\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Imprimir la precisión\n",
    "print(f\"Precisión del modelo: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Se cumple lo que dice la teoría en Hands-On Machine Learning with Scikit-Learn and TensorFlow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi caso no se cumple la teoria ya que Elu me ha dado mejores resultados que Selu e incluso diferentes metodos me han ido mejor que Selu, por ejemplo Selu me ha ha dado un valor de 0,22 mientras que Elu me ha dado un valor de 0,10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
